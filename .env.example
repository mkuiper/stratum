# LLM Configuration - Switch between providers
# Supported models:
#   OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
#   Google: gemini/gemini-2.0-flash-exp, gemini/gemini-1.5-pro
#   Ollama (local): ollama/llama3.2, ollama/mistral, ollama/qwen2.5
LLM_MODEL=gpt-4o
LLM_API_KEY=your_api_key_here
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4000

# Optional: Model-specific API keys (LiteLLM will auto-detect)
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GEMINI_API_KEY=...

# GROBID Citation Parser
GROBID_URL=http://localhost:8070/api

# Recursion Settings
MAX_DEPTH=3
MAX_CITATIONS_PER_PAPER=5

# Output Settings
OUTPUT_DIR=./output
CACHE_DIR=./data
